# LLM Provider Configuration
# Choose your LLM provider: 'openai' or 'anthropic'
LLM_PROVIDER=openai

# API Keys (set the one for your chosen provider)
OPENAI_API_KEY=your-openai-api-key-here
# ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Model Configuration
# OpenAI models: gpt-3.5-turbo, gpt-4, gpt-4-turbo-preview
# Anthropic models: claude-3-haiku-20240307, claude-3-sonnet-20240229, claude-3-opus-20240229
LLM_MODEL=gpt-3.5-turbo

# Generation Parameters
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=500

# ChromaDB Configuration
CHROMA_PERSIST_DIR=./chroma_db
CHROMA_COLLECTION_NAME=chatbot_docs

# Document Ingestion Configuration
CHUNK_SIZE=500
CHUNK_OVERLAP=50

# Support Bot Configuration
SUPPORT_BOT_COLLECTION=support_faq
SUPPORT_BOT_TOP_K=3
SUPPORT_BOT_FALLBACK="Thanks for reaching out! A specialist will reply shortly if this answer does not help."
# Optionally override the system prompt for the /support-bot/query endpoint
# SUPPORT_BOT_SYSTEM_PROMPT="You are SupportBot ..."
SUPPORT_ANALYTICS_FILE=analytics/support_metrics.json
# Optional JSON file describing tenant-specific overrides (see config/support_tenants.json)
SUPPORT_TENANT_CONFIG_PATH=config/support_tenants.json
